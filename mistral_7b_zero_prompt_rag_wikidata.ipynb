{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065f8b6a",
   "metadata": {},
   "source": [
    "### 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import demjson3\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from comet.models import download_model, load_from_checkpoint\n",
    "import os\n",
    "\n",
    "from entity_extraction import (\n",
    "    extract_capitalized_phrases,\n",
    "    extract_after_prepositions,\n",
    "    extract_quoted_entities,\n",
    "    extract_hyphenated_entities,\n",
    "    extract_entities_with_numbers_or_roman,\n",
    "    validate_entities\n",
    ")\n",
    "from framework import extract_entity_translation, calculate_comet_scores, calculate_meta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35f78f",
   "metadata": {},
   "source": [
    "### 2. Create prompt to extract entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"texts\"],\n",
    "    template='''You are a named entity recognition (NER) expert.\n",
    " \n",
    "For each of the following English sentences, extract all named entities (e.g., people, places, organizations, TV series, movies, books).\n",
    " \n",
    "Instructions:\n",
    "- ONLY extract named entities that appear EXACTLY and VERBATIM in the sentence.\n",
    "- DO NOT return alternate names, inferred references, or canonical forms.\n",
    "- DO NOT perform translation, rewriting, or guessing.\n",
    "- DO NOT infer likely entities or use context to deduce names.\n",
    "- An entity is valid ONLY if it is an exact substring match found in the sentence.\n",
    "- If an entity is not present word-for-word in the sentence, DO NOT include it.\n",
    "- DO NOT return partial entities or reformatted names.\n",
    " \n",
    "Output format:\n",
    "- Return a single JSON array.\n",
    "- Each item must be an object with these two fields:\n",
    "  - \"Source\": the original sentence.\n",
    "  - \"Entities\": a list of string values. Each string must be copied directly from the sentence. Each must be an exact substring of the Source.\n",
    " \n",
    "Rules:\n",
    "- DO NOT include any reasoning or commentary.\n",
    "- DO NOT include any Markdown formatting like triple backticks.\n",
    "- The output MUST be valid JSON that can be parsed by Python's json.loads().\n",
    " \n",
    "Texts:\n",
    "{texts}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fa1c2",
   "metadata": {},
   "source": [
    "### 3. Create prompt to verify and refine locally extracted candidate entities from a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_rethinking_prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\", \"candidate\"],\n",
    "    template=\"\"\"\n",
    "You are an expert in Named Entity Recognition (NER). Named entities can be people, places, organizations, TV series, movies, books, etc.\n",
    " \n",
    "Task:\n",
    "Given a sentence and a candidate phrase, your goal is to identify the **most complete named entity** from the sentence that includes the candidate. This helps verify whether the candidate is a full entity, a partial one, or invalid.\n",
    " \n",
    "Guidelines:\n",
    "- If the candidate is a **subset of a longer named entity**, return the **full entity** from the sentence as-is.\n",
    "- If the candidate **fully matches** a named entity in the sentence, return it.\n",
    "- If the candidate is **not part of any valid named entity** in the sentence, return an empty list.\n",
    "- Always return the named entity **verbatim**, exactly as it appears in the sentence (including casing, punctuation, etc.).\n",
    "- Do not add inferred terms or modify the sentence.\n",
    "- Named entities should not be a category or type.\n",
    " \n",
    "Response format:\n",
    "Return a valid JSON object with the following keys:\n",
    "- \"sentence\": the original input sentence.\n",
    "- \"entities\": a list with either the corrected entity string or an empty list if not found.\n",
    " \n",
    "Constraints:\n",
    "- Output only the JSON. No markdown, no code blocks, no commentary.\n",
    " \n",
    "Input:\n",
    "Sentence: \"{sentence}\"\n",
    "Candidate: \"{candidate}\"\n",
    " \n",
    "Output:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63560921",
   "metadata": {},
   "source": [
    "### 4. Create prompt to translate a sentence to respective language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0098c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\", \"language\", \"entities\"],\n",
    "    template=\"\"\"\n",
    "You are a professional translator with expertise in high-fidelity, fluent translations that preserve named entities.\n",
    " \n",
    "Translate the following English sentence into {language}. The translation MUST meet the following constraints:\n",
    " \n",
    "1. The meaning is preserved **accurately** and the sentence reads naturally to native speakers.\n",
    "2. All named entities from the list {entities} MUST appear in the translated sentence.\n",
    "3. Use **natural phrasing and correct grammar** in {language}.\n",
    "4. Avoid literal word-for-word translation and aim for native-like fluency.\n",
    "5. Do NOT hallucinate or modify entity names. Only translate using the list provided.\n",
    "6. Entity translation is mandatory unless it violates grammar or meaning in the {language}.\n",
    "7. If an entity cannot be translated after all attempts, only then include it in its English form.\n",
    "8. The output must be a valid JSON string that can be parsed by the Python json.loads() function.\n",
    "9. Ensure all JSON fields are correctly separated by commas. Do not omit commas between items or key-value pairs.\n",
    "10. Do not include any additional text or explanations.\n",
    " \n",
    "Format your response strictly as:\n",
    " \n",
    "{{\n",
    "  \"translation\": \"<natural and accurate translated sentence>\"\n",
    "  \"entities\": [\"<translated_entity1>\", \"<translated_entity2>\", ...]\n",
    "}}\n",
    " \n",
    "Sentence: \"{sentence}\"\n",
    "Entities: {entities}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ac7e7",
   "metadata": {},
   "source": [
    "### 5. Get folder and file path for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27c478-bd17-4db3-80ee-6f912a364a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_filepaths = {}\n",
    "\n",
    "def load_all_jsonl_files_by_language(folder_path):\n",
    "    lang_data = {}\n",
    "\n",
    "    for file_path in glob.glob(f\"{folder_path}/*.jsonl\"):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        lang_code = file_name.split(\"_\")[0]\n",
    "        language_filepaths[lang_code] = os.path.splitext(file_name)[0] \n",
    "\n",
    "        if lang_code not in lang_data:\n",
    "            lang_data[lang_code] = []\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                lang_data[lang_code].append(json.loads(line))\n",
    "\n",
    "    return lang_data\n",
    "\n",
    "\n",
    "def get_language_name(short_code):\n",
    "    lang_map = {\n",
    "        'ar': 'Arabic', 'zh': 'Chinese (Traditional)', 'fr': 'French', 'de': 'German',\n",
    "        'it': 'Italian', 'ja': 'Japanese', 'ko': 'Korean', 'es': 'Spanish',\n",
    "        'th': 'Thai', 'tr': 'Turkish', 'en': 'English'\n",
    "    }\n",
    "    return lang_map.get(short_code, short_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d0098",
   "metadata": {},
   "source": [
    "### 6. Retrieve data from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01059ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_folder = \"data/references/validation\"\n",
    "all_lang_data  = load_all_jsonl_files_by_language(jsonl_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d698a",
   "metadata": {},
   "source": [
    "### 7. Verify the loaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_code, records in all_lang_data.items():\n",
    "    print(f\"Loaded {len(records)} records for {get_language_name(lang_code)} ({lang_code})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d39322",
   "metadata": {},
   "source": [
    "### 8. Define LangChain with prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Ollama\n",
    "llm = OllamaLLM(model=\"mistral\")\n",
    "chain_extract = entity_extraction_prompt | llm\n",
    "chain_rethink = entity_rethinking_prompt | llm\n",
    "chain_translate = translation_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb5fdf",
   "metadata": {},
   "source": [
    "### 9. Extract named entities from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities_from_model(source):\n",
    "    try:\n",
    "        raw_entities = chain_extract.invoke({\"texts\": source})\n",
    "        entity_data = json.loads(raw_entities['text'])\n",
    "\n",
    "        return entity_data\n",
    "    except Exception:\n",
    "        try:\n",
    "            entity_data = demjson3.decode(raw_entities['text'])\n",
    "\n",
    "            return entity_data\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to recover batch with demjson3: {e2}\")\n",
    "            \n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b370c",
   "metadata": {},
   "source": [
    "### 10. Extract named entities locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967712e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities_locally(source):\n",
    "    return set(\n",
    "            extract_capitalized_phrases(source) +\n",
    "            extract_after_prepositions(source) +\n",
    "            extract_quoted_entities(source) +\n",
    "            extract_hyphenated_entities(source) +\n",
    "            extract_entities_with_numbers_or_roman(source)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242b5cb",
   "metadata": {},
   "source": [
    "### 11. Refine locally extracted entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_locally_extracted_entities(source, local_entities, cleaned_entity_list):\n",
    "    for entity in local_entities:\n",
    "        if entity not in cleaned_entity_list:\n",
    "            correction = chain_rethink.invoke({\"sentence\": source, \"candidate\": entity})\n",
    "                \n",
    "            try:\n",
    "                new_data = json.loads(correction['text'])\n",
    "            except json.JSONDecodeError as e:\n",
    "                try:\n",
    "                    new_data = demjson3.decode(correction['text'])\n",
    "                except Exception as e2:\n",
    "                    print(f\"Failed to recover batch with demjson3: {e2}\")\n",
    "                    continue\n",
    "                \n",
    "            if new_data.get('entities'):\n",
    "                cleaned_entity_list.extend(new_data['entities'])\n",
    "                cleaned_entity_list.append(entity)\n",
    "\n",
    "    return list(set([x.strip() for x in cleaned_entity_list if x.strip()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297e902",
   "metadata": {},
   "source": [
    "### 12. Remove duplicate entities (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ce34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_entities(cleaned_entity_list):\n",
    "    duplicate_entities = []\n",
    "    \n",
    "    for i in range(len(cleaned_entity_list)):\n",
    "        for j in range(len(cleaned_entity_list)):\n",
    "            if i != j and cleaned_entity_list[i] in cleaned_entity_list[j]:\n",
    "                duplicate_entities.append(cleaned_entity_list[i])\n",
    "\n",
    "    final_entity_list = []\n",
    "    for ent in cleaned_entity_list:\n",
    "        if ent not in duplicate_entities:\n",
    "            final_entity_list.append(ent)\n",
    "\n",
    "    return final_entity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc785cf8",
   "metadata": {},
   "source": [
    "### 13. Entity Translation via Retrieval (RAG Component), also includes finding the best match entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_named_entities(final_entity_list, lang_code):\n",
    "    model_entities = []\n",
    "    \n",
    "    for item in final_entity_list:\n",
    "        ent = extract_entity_translation(item, lang_code)\n",
    "            \n",
    "        if ent['qid']:\n",
    "            model_entities.append(ent['translated'])\n",
    "    \n",
    "    return model_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ead595",
   "metadata": {},
   "source": [
    "### 14. Perform translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(source, language, model_entities):\n",
    "    try:\n",
    "        raw_translated = chain_translate.invoke({\n",
    "            \"sentence\": source,\n",
    "            \"language\": language,\n",
    "            \"entities\": \", \".join(model_entities)\n",
    "        })\n",
    "        raw_translated = json.loads(raw_translated['text'])\n",
    "\n",
    "        return raw_translated\n",
    "    except Exception:\n",
    "        try:\n",
    "            raw_translated = demjson3.decode(raw_translated['text'])\n",
    "\n",
    "            return raw_translated\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to recover batch with demjson3: {e2}\")\n",
    "            \n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d5653",
   "metadata": {},
   "source": [
    "### 15. Begin zero - shot + RAG translation using LangChain for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de867744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_code, records in all_lang_data.items():\n",
    "    language = get_language_name(lang_code)\n",
    "\n",
    "    output_file = f\"data/predictions/mistral7b/zero_shot_rag_wikidata/{language_filepaths[lang_code]}.jsonl\"\n",
    "    results = []\n",
    "\n",
    "    for record in records:\n",
    "\n",
    "        source = record['source']\n",
    "        \n",
    "        # Extract named entities\n",
    "        entity_data = extract_named_entities_from_model(source)\n",
    "        \n",
    "        if (entity_data == None):\n",
    "            continue\n",
    "\n",
    "        local_entities = extract_named_entities_locally(source)\n",
    "\n",
    "        cleaned_entity_list = []\n",
    "        if isinstance(entity_data, dict):\n",
    "            cleaned_entity_list.extend(validate_entities(entity_data.get('Entities', []), source))\n",
    "        elif isinstance(entity_data, list):\n",
    "            for item in entity_data:\n",
    "                cleaned_entity_list.extend(validate_entities(item.get('Entities', []), source))\n",
    "\n",
    "        # Refine entities\n",
    "        cleaned_entity_list = refine_locally_extracted_entities(source, local_entities, cleaned_entity_list)\n",
    "        \n",
    "        # Remove duplicate entries\n",
    "        final_entity_list = remove_duplicate_entities(cleaned_entity_list)\n",
    "\n",
    "        # Translate named entities using Wikidata\n",
    "        model_entities = translate_named_entities(final_entity_list, record['target_locale'])\n",
    "\n",
    "        # Translate sentence\n",
    "        raw_translated = translate_sentence(source, language, model_entities)\n",
    "\n",
    "        if (raw_translated == None):\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            \"id\": record['id'],\n",
    "            \"text\": source,\n",
    "            \"source_language\": record['source_locale'],\n",
    "            \"target_language\": record['target_locale'],\n",
    "            \"prediction\": raw_translated['translation'],\n",
    "        })\n",
    "        \n",
    "        # Record the results to a file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for res in results:\n",
    "                f.write(json.dumps(res, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c1278",
   "metadata": {},
   "source": [
    "### 16. Define folder and file structure to save M-ETA and COMET scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "comet_model = load_from_checkpoint(comet_model_path)\n",
    "model_name = \"mistral7b\"\n",
    "output_prediction_dir = os.path.join(\"data/predictions\", model_name)\n",
    "os.makedirs(output_prediction_dir, exist_ok=True)\n",
    "\n",
    "input_data_folder = \"data/references/validation\"\n",
    "jsonl_files = glob.glob(f\"{input_data_folder}/*.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff7751",
   "metadata": {},
   "source": [
    "### 17. COMET and M-ETA scores calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1210a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(template_id):\n",
    "    scores_dir = os.path.join(output_prediction_dir, template_id, \"scores\")\n",
    "    \n",
    "    if not os.path.exists(scores_dir):\n",
    "        os.makedirs(scores_dir, exist_ok=True)\n",
    "\n",
    "    for file_path in jsonl_files:\n",
    "        references_path = file_path\n",
    "        filename = os.path.basename(file_path)\n",
    "        predictions_path = os.path.join(output_prediction_dir, template_id, filename)\n",
    "\n",
    "        comet_score = calculate_comet_scores(\n",
    "            comet_model, \n",
    "            references_path, \n",
    "            predictions_path\n",
    "        )\n",
    "\n",
    "        correct_instances, total_instances, meta_score = calculate_meta_score(\n",
    "            references_path,\n",
    "            predictions_path)\n",
    "\n",
    "        evaluation_results = {\n",
    "            \"correct_instances\": correct_instances,\n",
    "            \"total_instances\": total_instances,\n",
    "            \"comet_score\": comet_score,\n",
    "            \"meta_score\": meta_score\n",
    "        }\n",
    "\n",
    "        evaluation_output_path = os.path.join(scores_dir, filename)\n",
    "        with open(evaluation_output_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(evaluation_results, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe9f17",
   "metadata": {},
   "source": [
    "### 18. Calculate COMET and M-ETA scores for quality evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7360495",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_scores(\"zero_shot_rag_wikidata\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
